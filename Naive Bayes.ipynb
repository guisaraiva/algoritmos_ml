{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importação das bibliotecas que serão utilizadas na aprendizagem do Naive Bayes.\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando o arquivo contendo os dados que serão analisados durante a aprendizagem.\n",
    "\n",
    "dados = pd.read_csv('tweets_mg.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando o método info() para retornar informações sobre o conjunto de dados.\n",
    "# Podemos observar no retorno do método todas as colunas e informações do conjunto de dados.\n",
    "\n",
    "dados.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizamos o pacote pandas para visualizar o tamanho total da coluna \"Text\" que contém os tweets.\n",
    "# Estou exibindo apenas os 100 primeiros registros através do parâmetro passado para o head().\n",
    "# Mais informações sobre o set_option e as opções de parâmetros no link abaixo.\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.set_option.html \n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "dados.Text.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Existem linhas duplicadas no conjunto de dados.\n",
    "# Com o método drop_duplicates() podemos remover os dados de uma determinada colunaa do conjunto de dados.\n",
    "# Devemos passar a coluna desejada dentro do colchetes e entre aspas simples.\n",
    "\n",
    "dados.drop_duplicates(['Text'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos contar a quantidade de dados existentes no conjunto após a exclusão de registros duplicados.\n",
    "\n",
    "dados.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Após a remoção de linhas duplicadas, vamos remover colunas desnecessárias para nossa análise.\n",
    "# A exclusão de informações é realizada com base na análise de cada pessoa. \n",
    "# A preparação da base de dados é uma parte fundamental no processo de análise de dados.\n",
    "# Temos um loop For iterando no conjunto de dados e removendo a coluna \"Unnamed\".\n",
    "\n",
    "for i in dados.columns.values:\n",
    "    if i.startswith('Unnamed'):\n",
    "        dados.drop(i, axis=1, inplace=True)\n",
    "        print ('Colunas Deletadas:', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando as colunas do conjuntos de dados após a exclusão das informações desnecessárias.\n",
    "dados.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando apenas as informações da coluna \"Classificação\".\n",
    "# A coluna Classificação possuí a classifiação feita para cada tweet de forma manual.\n",
    "# A classificação está definida como Neutro, Positivo, Negativo.\n",
    "\n",
    "dados.Classificacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passando o matplotlib inline para visualizar o gráfico no próprio jupyter notebook.\n",
    "%matplotlib inline\n",
    "\n",
    "# Plotando a coluna classificação no gráfico e contando a quantidade de cada classificação no conjunto de dados.\n",
    "# Vamos plotar um gráfico do tipo bar. Podemos observar o parâmetro kind definido abaixo.\n",
    "\n",
    "dados.Classificacao.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizando uma separação dos tweets e suas respectivas classes.\n",
    "# Estamos realizando a separação dos dados para realizar o treino posteriormente.\n",
    "# Estamos armazenando uma coluna do conjunto de dados em cada variável criada.\n",
    "\n",
    "tweets = dados['Text']\n",
    "classes = dados['Classificacao']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando o modelo através do metódo CountVectorizer, passando o parâmetro \"word\".\n",
    "# Estamos dizendo para o modelo analisar cada palavra com base no bag of words.\n",
    "# Na variável freq_tweets armazenamos a transformação da variável tweets criada anteriormente.\n",
    "\n",
    "vetor = CountVectorizer(analyzer=\"word\")\n",
    "freq_tweets = vetor.fit_transform(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos visualuzar o tipo da variável freq_tweets. O resulta é uma matriz esparsa.\n",
    "\n",
    "type(freq_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibindo o resulta da matriz esparsa criada anteriormente. \n",
    "# O conjunto de dados pos\n",
    "\n",
    "freq_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos utilizar o modelo Multinomial do Naive Bayes.\n",
    "# Existem os seguintes modelos no Naive Bayes (Bernoulli Naive Bayes, Gaussian Naive Bayes, Multinomial Naive Bayes)\n",
    "\n",
    "modelo = MultinomialNB()\n",
    "modelo.fit(freq_tweets,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos testar o modelo criado passando algumas instâncias simples. Foram criadas de forma aleatória.\n",
    "# Uma variável testes para receber instâncias que serão testadas pelo nosso modelo posteriormente.\n",
    "\n",
    "testes = ['Esse governo está no início e é uma droga',\n",
    "          'Estou feliz com o governo de Minas esse ano. Acho que podemos esperar coisas boas',\n",
    "          'O estado de Minas Gerais decretou calamidade financeira!!! Socorro !!!!',\n",
    "          'A segurança desse país é uma droga',\n",
    "          'O governador de Minas é mais uma vez do PT. Eh Brasil !!!!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforma os dados de teste em vetores de palavras.\n",
    "\n",
    "freq_testes = vetor.transform(testes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizando a classificação com o modelo treinado anteriormente.\n",
    "# Utilizando o loopt for para exibir os resultados de cada \"frase\" criada anteriormente.\n",
    "\n",
    "for t, c in zip (testes,modelo.predict(freq_testes)):\n",
    "    print (t +\", \"+ c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilidades de cada classe do conjunto de dados.\n",
    "# Usamos o predict_proba para visualizar os dados de probabilidade. \n",
    "# A visualização será um array com cada frase em sua respectiva posição.\n",
    "\n",
    "print (modelo.classes_)\n",
    "modelo.predict_proba(freq_testes).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos realizar uma avaliação do modelo utilizando a técnica de \"Cross Validation\"\n",
    "# Utilizaremos com 10 folds. Mais informações no link abaixo:\n",
    "# https://scikit-learn.org/stable/modules/cross_validation.html\n",
    "\n",
    "resultados = cross_val_predict(modelo, freq_tweets, classes, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Utilizando a matriz de confusão. Essa técnica é excelente para validação.\n",
    "# Temos como analisar os dados que foram interpretados em classes \"incorretas\".\n",
    "\n",
    "print (pd.crosstab(classes, resultados, rownames=['Real'], colnames=['Predito'], margins=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos umsar o método metrics do sklearn. Vale a pena uma leitura na documentação. \n",
    "# https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n",
    "\n",
    "sentimento=['Positivo','Negativo','Neutro']\n",
    "print (metrics.classification_report(classes,resultados,sentimento))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos aplicar o tunning no algoritmo Naive Bayes.\n",
    "# Usamos o tunning para executar o modelo por várias vezes alterando o parâmetro.\n",
    "# Importar o GridSearchCV do pacote abaixo.\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação de uma variável para receber um lista com range de 1 até 10.\n",
    "# Iremos utilizar posteriormente a variável criada.\n",
    "\n",
    "lista_alpha = list(range(1,11))\n",
    "lista_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um dicionário com o nome do parâmetro e a lista de valores.\n",
    "# Repare que a chave do diicionário é o nome do parâmetro do modelo MultinomialNB().\n",
    "\n",
    "parametros_grid = dict(alpha=lista_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciando o modelo através da variável nvModelo. Já criei uma variável modelo anteriormente.\n",
    "\n",
    "nvModelo = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crianndo o objeto grid passando o metódo GridSearchCV com os respectivos parâmetros.\n",
    "# Podemos observar que passei o modelo criado, o dicionário com o range de valores, quantidade de folds e o scoring.\n",
    "\n",
    "grid = GridSearchCV(nvModelo, parametros_grid, cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos executar o objeto grid criado anteriormente. \n",
    "# Ao executar o script abaixo, vamos ter como resultado os parâmetros. \n",
    "# Podemos visualizar o param_grid contendo os dados do dicionário criado anteriormente.\n",
    "\n",
    "freq_tweets = vetor.fit_transform(tweets)\n",
    "grid.fit(freq_tweets, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos visualizar quais são os melhores scores com o metódo best_score_\n",
    "# Documentação do GridSearchCV no link abaixo:\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "\n",
    "grid.best_score_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando qual foi o melhor parâmetro. Com base no dicionário de parâmetros criados anteriormente.\n",
    "\n",
    "grid.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
