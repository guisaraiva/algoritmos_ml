{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas utilizadas no algoritmo SVM\n",
    "# sklearn.model_selection (utilizamos para dividir o dataset em treino e teste posteriormente.)\n",
    "# Matplotlib (biblioteca gráfica)\n",
    "# Uma ótima leitura na documentação do Sklearn (https://scikit-learn.org/stable/modules/classes.html#module-sklearn.svm)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação do dataset IRIS. Esse conjunto de dados é simples e de fácil manipulação.\n",
    "# Irei começar a executação do algoritmo nessa base de dados e posteriormente utilizei um dataset spotfy.\n",
    "\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o dataset para o array chamado iris\n",
    "# A partir do sklearn podemos carregar o dataset sem a necessidade de importação de arquivo externo.\n",
    "# Em outros algoritmos, realizei a importação do dataset através de um arquivo.\n",
    "\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Um método que já aprendi anteriormente.\n",
    "# O type() retorna o tipo de uma variável criada anteriormente.\n",
    "\n",
    "type(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando o nome das features\n",
    "# Podemos chamar vários métodos no objeto iris.\n",
    "# Lembrando que estou usando os métodos pois não carregamos os dados de arquivo externo.\n",
    "# Coisas novas por causa do sklearn.\n",
    "\n",
    "iris.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nome das Classes\n",
    "# Repare que é um array. Podemos identificar pelo colchete []\n",
    "\n",
    "iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando dados de treino.\n",
    "# Armazenando os dados do dataset em uma variável treino.\n",
    "\n",
    "treino = iris.data\n",
    "#treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando dados de classes. \n",
    "# Criei um variável chamada classe. Poderia ser qualquer nome.\n",
    "\n",
    "classe = iris.target\n",
    "#classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando a forma do array dos dados de treino. Formato (linhas,colunas).\n",
    "# O resultado é organizado conforme explicado anteriormente. 150 linhas com 4 colunas.\n",
    "\n",
    "treino.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando os dados de treino.\n",
    "# Passei o parâmetro :20. Vai exibir os 20 últimos registros do dataset de treino.\n",
    "\n",
    "treino[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando a forma do array de classes.\n",
    "# Na classe, vamos observar apenas as informações de 150 registros.\n",
    "\n",
    "classe.shape\n",
    "#classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando os dados únicos do array de classes.\n",
    "# O set executa a mesma ação que um comando distinct (oracle) !! Pra lembrar melhor !! :)\n",
    "set(classe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando os dados de classes.\n",
    "\n",
    "classe[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualização de dados. Visualizando a disperssão de dados quanto a classe\n",
    "# Agora posso usar a biblioteca matplotlib para plotar os gráficos com as respectivas features.\n",
    "# Plota gráfico de disperssão dos dados com relação a classe.\n",
    "# Disperssão dos dados de Sepal width e Sepal Length com as classes(0,1,2)\n",
    "# Documentação para ajudar a entender melhor (https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.scatter.html)\n",
    "\n",
    "%matplotlib notebook\n",
    "from matplotlib import style\n",
    "style.use(\"ggplot\") # O stilo definido para o gráfico.\n",
    "#sepal length vs sepal width\n",
    "plt.xlabel('Sepal length') # A descrição do eixo X\n",
    "plt.ylabel('Sepal width') # A descrição do eixo Y\n",
    "plt.title('Sepal width vs Sepal length') # O título do gráfico.\n",
    "plt.scatter(treino[:,0],treino[:,1], c=classe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plota gráfico de disperssão dos dados com relação a classe.\n",
    "# Disperssão dos dados de Petal width e Petal Length com as classes(0,1,2)\n",
    "\n",
    "%matplotlib notebook\n",
    "from matplotlib import style\n",
    "style.use(\"ggplot\")\n",
    "plt.xlabel('Petal length')\n",
    "plt.ylabel('Petal width')\n",
    "plt.title('Petal Width vs Petal Length')\n",
    "plt.scatter(treino[:,2], treino[:,3], c=classe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar a aplicação do algoritmo SVM para classificar as flores usando o dataset IRIS.\n",
    "# Pegar 80% dos dados para treino e 20% para teste (Normalmente pegamos essa quantidade).\n",
    "\n",
    "# Visualizando o tamanho dos dados de treino.\n",
    "# O parâmetro -30 é para retirar os apenas os dados necessários para treino.\n",
    "# Os demais serão utilizados para teste.\n",
    "\n",
    "len(treino[:-30]), len(classe[:-30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando os dados de treino\n",
    "\n",
    "treino[:-30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiando as classes correspondentes\n",
    "# A classe desse bloco de execução pertence aos dados de treino.\n",
    "\n",
    "classe[:-30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinando o algoritmo de SVM. Agora começa a brincadeira !!! ;)\n",
    "# O método fit sendo invocado para treinar os dados.\n",
    "\n",
    "\n",
    "classificadorSVM = svm.SVC().fit(treino[:-30],classe[:-30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objeto classificadorSVM\n",
    "# Analisando o resultado podemos observar vários parâmetros que existem no SVC.\n",
    "# Vou deixar todos parâmetros com os valores padrões.\n",
    "\n",
    "classificadorSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria um array com os dados de teste.\n",
    "# 20% dos dados que não foram testados.\n",
    "# Lembrando que separei os 80% do dataset anteriormente.\n",
    "\n",
    "teste = treino[-30:]\n",
    "teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predizendo valores com a porção de dados de teste.\n",
    "# Chamamos o objeto criado com o método predict do SVN.\n",
    "# Passamos os dados de teste 20%\n",
    "\n",
    "classificadorSVM.predict(teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria um array com as classes dos dados de teste.\n",
    "\n",
    "classe_teste = classe[-30:]\n",
    "classe_teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando os Resultados de Classificação.\n",
    "# Gráfico de disperssão entre as colunas Sepal Length , Sepatl width e a classe.\n",
    "# Os pontos roxos são pontos no qual o classificador errou.\n",
    "\n",
    "%matplotlib notebook\n",
    "from matplotlib import style\n",
    "style.use(\"ggplot\")\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "plt.title('Sepal width vs Sepal length')\n",
    "plt.scatter(treino[-30:,0],treino[-30:,1], c=classificadorSVM.predict(teste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de disperssão entre as colunas Petal Length , Petal width e a classe.\n",
    "\n",
    "%matplotlib notebook\n",
    "from matplotlib import style\n",
    "style.use(\"ggplot\")\n",
    "plt.xlabel('Petal length')\n",
    "plt.ylabel('Petal width')\n",
    "plt.title('Petal Width vs Length')\n",
    "plt.scatter(treino[-30:,2], treino[-30:,3], c=classificadorSVM.predict(teste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de instâncias e predição destas.\n",
    "\n",
    "%matplotlib notebook\n",
    "from matplotlib import style\n",
    "style.use(\"ggplot\")\n",
    "plt.xlabel('Amostras')\n",
    "plt.ylabel('Classes')\n",
    "plt.title('Classificacao do SVM')\n",
    "plt.scatter(range(len(classe_teste)),classe_teste,c=classificadorSVM.predict(teste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizando a matriz de confusão.\n",
    "# Link com referência massa: https://minerandodados.com.br/matriz-de-confusao/\n",
    "# No resultado da matriz, o algoritmo preveu um 2 como 1 em cinco momentos.\n",
    "\n",
    "print (pd.crosstab(classe_teste,classificadorSVM.predict(teste),rownames=['Real'], colnames=['Predito'], margins=True),'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando o Cross Validation.\n",
    "# Link com uma explicação sobre Cross Validation \n",
    "# (https://medium.com/data-hackers/como-criar-k-fold-cross-validation-na-m%C3%A3o-em-python-c0bb06074b6b)\n",
    "\n",
    "# Criei uma função que retorna a acurácia após fazer um validação cruzada (cross validation)\n",
    "\n",
    "\n",
    "def Acuracia(classificadorSVM,X,y):\n",
    "    resultados = cross_val_predict(classificadorSVM, X, y, cv=10)\n",
    "    return metrics.accuracy_score(y,resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chamado a função criada anteriormente e passando os parâmetros necessários para análise.\n",
    "# Uma acurácia de 98% é boa.... \n",
    "\n",
    "Acuracia(classificadorSVM,treino,classe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizar métricar de avaliação.\n",
    "# Imprime as métricas: 'precisão, revocação e Medida F1.\n",
    "# Link massa para absorção de conhecimento:\n",
    "# https://paulovasconcellos.com.br/como-saber-se-seu-modelo-de-machine-learning-est%C3%A1-funcionando-mesmo-a5892f6468b\n",
    "\n",
    "# Armazenando o resultado do cross validation na variável resultados.\n",
    "resultados = cross_val_predict(classificadorSVM,treino, classe, cv=10)\n",
    "\n",
    "# Criando valores fixos\n",
    "valor_classes = [0,1,2]\n",
    "\n",
    "# Exibindo as métricas de avaliação através do classifcation_report do pacote sklearn\n",
    "print (metrics.classification_report(classe,resultados,valor_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informações das Features da Base de dados.\n",
    "# https://developer.spotify.com/web-api/get-audio-features/\n",
    "# Vou aplicar o algoritmo em uma outra base de dados. Uma base de dados do Spotfy para realizarmos a aplicação do SVM.\n",
    "# Vamos ver no que vai dá !!!\n",
    "dataset = pd.read_csv('data.csv', sep=',')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisando os respectivos dados. Checando valores missing.\n",
    "# O termo missing é muito utilizado em análise de dados. Valores ausentes ...\n",
    "# Estou pedindo para exibir o total de valores nulos que existem no dataset.\n",
    "\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Resumo Estatístico da base. Somente dados numéricos.\n",
    "# O describe é um excelente método estatístico.\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html\n",
    "\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lista estilos disponíveis do Matplotlib.\n",
    "# Um método interessante para verificar quais estilos de gráficos estão disponíveis no Matplotlib.\n",
    "# https://matplotlib.org/3.1.1/gallery/style_sheets/style_sheets_reference.html\n",
    "\n",
    "plt.style.available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vou plotar vários gráficos comparando as features do dataset.\n",
    "# A comparação está ocorrendo com features analisadas anterioremente.\n",
    "\n",
    "%matplotlib notebook\n",
    "from matplotlib import style\n",
    "style.use(\"seaborn-colorblind\")\n",
    "dataset.plot(x='acousticness', y='danceability', c='target', kind='scatter', colormap='Accent_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from matplotlib import style\n",
    "style.use(\"seaborn-colorblind\")\n",
    "dataset.plot(x='tempo', y='valence', c='target', kind='scatter' , colormap='Accent_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from matplotlib import style\n",
    "style.use(\"seaborn-colorblind\")\n",
    "dataset.plot(x='tempo', y='speechiness', c='target', kind='scatter' , colormap='Accent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from matplotlib import style\n",
    "style.use(\"seaborn-colorblind\")\n",
    "dataset.plot(x='danceability', y='energy', c='target', kind='scatter' , colormap='Reds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Começando a realizar a separação do dataset em treino e teste.\n",
    "# Estou armazenando a variável target e posteriormente realizando a exclusão dela do dataset.\n",
    "\n",
    "classesSpotfy = dataset['target']\n",
    "dataset.drop('target', axis=1, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando os 15 primeiros registros do daataset\n",
    "dataset.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar um pré-processamento dos dados. \n",
    "# A função remove_features executa a remoção de features que serão passadas como parâmetro posteriormente.\n",
    "# Estou apenas criando a função neste momento.\n",
    "\n",
    "\n",
    "def remove_features(lista_features):\n",
    "    for i in lista_features:\n",
    "        dataset.drop(i, axis=1, inplace=True)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove features. Observe que estou passando duas features através de um array.\n",
    "# O retorno é 0.\n",
    "\n",
    "remove_features(['id','song_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando o dataset após aplicação dos comandos anteriores.\n",
    "\n",
    "dataset.artist.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando o dataset com o método info()\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vou sar o Label Encoder. Essa técnica codifica valores categóricos em numéricos.\n",
    "# Realizando a importação do Label Encoder.\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instânciando o labelEncoder\n",
    "lEncoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando o fit_transform do labelEncoder. \n",
    "# Transformando a feature \"artist\" e dados numéricos.\n",
    "\n",
    "inteiro = lEncoder.fit_transform(dataset['artist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando valores únicos. Lembrar do distinct (oracle)\n",
    "\n",
    "set(inteiro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estou criando uma nova colun \"artist_inteiro\" que recebe os dados transformados.\n",
    "\n",
    "dataset['artist_inteiro'] = inteiro\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_features(['artist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando o Dataset alterado.\n",
    "dataset.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa o pacote OneHotEncoder\n",
    "# Técnica usada para codificar valores categóricos em númericos.\n",
    "# Resolve o problema __ordenação__ nos dados gerados pelo LabelEncoder.\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancia um objeto do tipo OnehotEncoder\n",
    "\n",
    "oHE = OneHotEncoder()\n",
    "dataset.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforma em array numpy o dataset.\n",
    "\n",
    "dataset_array = dataset.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pega o numero de linhas.\n",
    "num_rows = dataset_array.shape[0]\n",
    "\n",
    "# Visualiza coluna de inteiros\n",
    "dataset_array[:][:,13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforma a matriz em uma dimensão\n",
    "\n",
    "inteiro = inteiro.reshape(len(inteiro),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar as novas features a partir da matriz de presença.\n",
    "novas_features = oHE.fit_transform(inteiro)\n",
    "\n",
    "# Imprime as novas features\n",
    "novas_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatena as novas features ao array\n",
    "dataset_array = np.concatenate([dataset_array, novas_features.toarray()], axis=1)\n",
    "\n",
    "# Visualizando a quantidade de linhas e colunas da base\n",
    "dataset_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforma em dataframe e visualiza as colunas\n",
    "dataf = pd.DataFrame(dataset_array)\n",
    "dataf.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando o get_dummies nos dados.\n",
    "# Cria uma matriz de presença como feito com o OHE.\n",
    "# Vamos importar novamente o dataset.\n",
    "\n",
    "#dataset = pd.read_csv('data.csv', sep=',')\n",
    "dataset = pd.get_dummies(dataset, columns=['artist'], prefix=['artist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando 'features' geradas.\n",
    "\n",
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando o tamanho.\n",
    "\n",
    "len(dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando as colunas\n",
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checando missing values\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coluna artist\n",
    "len(dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizando o Pipeline\n",
    "# Importe as bibliotecas de Pipelines e Pré-processadores (normalização - standartization.\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classesSpotfy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinando o algoritmo de SVM.\n",
    "classifSVM = svm.SVC().fit(dataset,classesSpotfy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chamando novamente a função criada anteriormente.\n",
    "\n",
    "Acuracia(classifSVM,dataset,classesSpotfy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um pipeline \n",
    "# Podemos observar que estamos normalizando os dados com o pipeline.\n",
    "\n",
    "pip_1 = Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('clf', svm.SVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimindo Etapas do Pipeline\n",
    "pip_1.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chama a função acuracia passando os dados de musicas e as classes\n",
    "# Usando o pipeline pip_1\n",
    "\n",
    "Acuracia(pip_1,dataset,classesSpotfy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando vários Pipelines\n",
    "pip_2 = Pipeline([\n",
    "    ('min_max_scaler', MinMaxScaler()),\n",
    "    ('clf', svm.SVC())\n",
    "])\n",
    "\n",
    "pip_3 = Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('clf', svm.SVC(kernel='rbf'))\n",
    "])\n",
    "\n",
    "pip_4 = Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('clf', svm.SVC(kernel='poly'))\n",
    "])\n",
    "\n",
    "pip_5 = Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('clf', svm.SVC(kernel='linear'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chama a função acuracia passando os dados de musicas e as classes\n",
    "# Usando o pipeline pip_2\n",
    "Acuracia(pip_2,dataset,classesSpotfy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste com apenas labelEncoder nos dados\n",
    "# Teste com apenas LabelEncoder na coluna 'artist' usando o pipeline 'pip_1'\n",
    "\n",
    "Acuracia(pip_1,dataset,classesSpotfy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Teste com apenas LabelEncoder na coluna 'artist' usando o pipeline 'pip_2'\n",
    "\n",
    "Acuracia(pip_2,dataset,classesSpotfy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testando o desempenho dos kernels.\n",
    "# Testando o Kernel RBF\n",
    "\n",
    "Acuracia(pip_3,dataset,classesSpotfy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste de kernel poly\n",
    "Acuracia(pip_4,dataset,classesSpotfy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste de Kernel linear\n",
    "Acuracia(pip_5,dataset,classesSpotfy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizando o tunning nos dados. \n",
    "# Importa o utilitário GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de Valores de C\n",
    "lista_C = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "# Lista de Valores de gamma\n",
    "lista_gamma = [0.001, 0.01, 0.1, 1, 10, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define um dicionário que recebe as listas de parâmetros e valores.\n",
    "\n",
    "parametros_grid = dict(clf__C=lista_C, clf__gamma=lista_gamma)\n",
    "parametros_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objeto Grid recebe parâmetros de Pipeline, e configurações de cross validation\n",
    "grid = GridSearchCV(pip_3, parametros_grid, cv=10, scoring='accuracy')\n",
    "\n",
    "# Aplica o gridsearch passando os dados de treino e classes.\n",
    "grid.fit(dataset,classesSpotfy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultados de Grid\n",
    "# Imprime os scores por combinações\n",
    "grid.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime os melhores parâmetros\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_score_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
